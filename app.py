
import subprocess
from PyQt5.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QLineEdit,
    QPushButton, QHBoxLayout, QLabel, QScrollArea, QDesktopWidget,
    QMainWindow, QAction, QMenu, QDialog, QFormLayout, QDoubleSpinBox,
    QSpinBox, QComboBox, QCheckBox, QTabWidget, QGroupBox, QSlider,
    QFileDialog, QInputDialog, QMessageBox, QDialogButtonBox
)
from PyQt5.QtGui import QFont, QPalette, QColor, QIcon
from PyQt5.QtCore import Qt, QObject, pyqtSignal, QThread
from langchain_community.chat_models import ChatOllama
from langchain.callbacks.base import BaseCallbackHandler
from langchain.prompts import ChatPromptTemplate
from langchain.memory import ConversationBufferMemory
import json
import os

import shutil
import psutil
import platform
import GPUtil
import sys
import logging

# Set up logging
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')

class StreamHandler(QObject, BaseCallbackHandler):
    new_token = pyqtSignal(str)

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        try:
            self.new_token.emit(token)
        except Exception as e:
            logging.error(f"Error in StreamHandler: {str(e)}")

class ChatThread(QThread):
    response_ready = pyqtSignal(str)
    error_occurred = pyqtSignal(str)
    
    def __init__(self, llm, messages):
        super().__init__()
        self.llm = llm
        self.messages = messages
    
    def run(self):
        try:
            response = self.llm.invoke(self.messages)
            self.response_ready.emit(response.content)
        except Exception as e:
            logging.error(f"Error in ChatThread: {str(e)}")
            if "503" in str(e):
                self.error_occurred.emit("Error: Unable to connect to Ollama. Please ensure that any VPN or proxy is turned off.")
            else:
                self.error_occurred.emit(str(e))
            

class MessageWidget(QWidget):
    def __init__(self, message, is_user=True):
        super().__init__()
        try:
            layout = QHBoxLayout()
            text = QLabel(message)
            text.setWordWrap(True)
            text.setFont(QFont('Arial', 12))
            
            if is_user:
                layout.addStretch()
                text.setStyleSheet("background-color: #DCF8C6; border-radius: 10px; padding: 10px;")
            else:
                text.setStyleSheet("background-color: #FFFFFF; border-radius: 10px; padding: 10px;")
            
            layout.addWidget(text)
            
            if not is_user:
                layout.addStretch()
            
            self.setLayout(layout)
        except Exception as e:
            logging.error(f"Error in MessageWidget: {str(e)}")

class SettingsDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        try:
            self.setWindowTitle("Settings")
            self.layout = QVBoxLayout(self)

            # Create tabs
            self.tabs = QTabWidget()
            self.layout.addWidget(self.tabs)

            # Model Settings Tab
            self.model_tab = QWidget()
            self.model_layout = QFormLayout(self.model_tab)
            self.tabs.addTab(self.model_tab, "Model Settings")

            self.temperature = QDoubleSpinBox()
            self.temperature.setRange(0, 2)
            self.temperature.setSingleStep(0.1)
            self.temperature.setValue(0.8)

            self.num_ctx = QSpinBox()
            self.num_ctx.setRange(1, 8192)
            self.num_ctx.setValue(2048)

            self.num_gpu = QSpinBox()
            self.num_gpu.setRange(0, 8)
            self.num_gpu.setValue(1)

            self.num_thread = QSpinBox()
            self.num_thread.setRange(1, 32)
            self.num_thread.setValue(4)

            self.top_k = QSpinBox()
            self.top_k.setRange(1, 100)
            self.top_k.setValue(40)

            self.top_p = QDoubleSpinBox()
            self.top_p.setRange(0, 1)
            self.top_p.setSingleStep(0.05)
            self.top_p.setValue(0.9)

            self.repeat_penalty = QDoubleSpinBox()
            self.repeat_penalty.setRange(0, 2)
            self.repeat_penalty.setSingleStep(0.1)
            self.repeat_penalty.setValue(1.1)

            self.repeat_last_n = QSpinBox()
            self.repeat_last_n.setRange(0, 2048)
            self.repeat_last_n.setValue(64)

            self.seed = QSpinBox()
            self.seed.setRange(-1, 2147483647)  # Changed to avoid overflow
            self.seed.setValue(-1)

            self.mirostat = QComboBox()
            self.mirostat.addItems(["0", "1", "2"])

            self.mirostat_tau = QDoubleSpinBox()
            self.mirostat_tau.setRange(0, 10)
            self.mirostat_tau.setSingleStep(0.1)
            self.mirostat_tau.setValue(5.0)

            self.mirostat_eta = QDoubleSpinBox()
            self.mirostat_eta.setRange(0, 1)
            self.mirostat_eta.setSingleStep(0.01)
            self.mirostat_eta.setValue(0.1)

            self.f16_kv = QCheckBox()
            self.logits_all = QCheckBox()
            self.vocab_only = QCheckBox()

            self.model_layout.addRow("Temperature:", self.temperature)
            self.model_layout.addRow("Context Length:", self.num_ctx)
            self.model_layout.addRow("Number of GPUs:", self.num_gpu)
            self.model_layout.addRow("Number of Threads:", self.num_thread)
            self.model_layout.addRow("Top K:", self.top_k)
            self.model_layout.addRow("Top P:", self.top_p)
            self.model_layout.addRow("Repeat Penalty:", self.repeat_penalty)
            self.model_layout.addRow("Repeat Last N:", self.repeat_last_n)
            self.model_layout.addRow("Seed:", self.seed)
            self.model_layout.addRow("Mirostat:", self.mirostat)
            self.model_layout.addRow("Mirostat Tau:", self.mirostat_tau)
            self.model_layout.addRow("Mirostat Eta:", self.mirostat_eta)
            self.model_layout.addRow("Use F16 KV:", self.f16_kv)
            self.model_layout.addRow("Logits All:", self.logits_all)
            self.model_layout.addRow("Vocab Only:", self.vocab_only)

            # UI Settings Tab
            self.ui_tab = QWidget()
            self.ui_layout = QFormLayout(self.ui_tab)
            self.tabs.addTab(self.ui_tab, "UI Settings")

            self.font_size = QSpinBox()
            self.font_size.setRange(8, 24)
            self.font_size.setValue(12)

            self.theme = QComboBox()
            self.theme.addItems(["Light", "Dark", "System"])

            self.chat_bubble_color = QComboBox()
            self.chat_bubble_color.addItems(["Blue", "Green", "Gray"])

            self.ui_layout.addRow("Font Size:", self.font_size)
            self.ui_layout.addRow("Theme:", self.theme)
            self.ui_layout.addRow("Chat Bubble Color:", self.chat_bubble_color)

            # Advanced Settings Tab
            self.advanced_tab = QWidget()
            self.advanced_layout = QFormLayout(self.advanced_tab)
            self.tabs.addTab(self.advanced_tab, "Advanced Settings")

            self.max_tokens = QSpinBox()
            self.max_tokens.setRange(1, 8192)
            self.max_tokens.setValue(2048)

            self.stop_sequences = QLineEdit()
            self.stop_sequences.setPlaceholderText("Enter stop sequences separated by comma")

            self.presence_penalty = QDoubleSpinBox()
            self.presence_penalty.setRange(-2.0, 2.0)
            self.presence_penalty.setSingleStep(0.1)
            self.presence_penalty.setValue(0.0)

            self.frequency_penalty = QDoubleSpinBox()
            self.frequency_penalty.setRange(-2.0, 2.0)
            self.frequency_penalty.setSingleStep(0.1)
            self.frequency_penalty.setValue(0.0)

            self.advanced_layout.addRow("Max Tokens:", self.max_tokens)
            self.advanced_layout.addRow("Stop Sequences:", self.stop_sequences)
            self.advanced_layout.addRow("Presence Penalty:", self.presence_penalty)
            self.advanced_layout.addRow("Frequency Penalty:", self.frequency_penalty)

            # Memory Settings Tab
            self.memory_tab = QWidget()
            self.memory_layout = QFormLayout(self.memory_tab)
            self.tabs.addTab(self.memory_tab, "Memory Settings")

            self.memory_type = QComboBox()
            self.memory_type.addItems(["ConversationBufferMemory", "ConversationBufferWindowMemory", "ConversationSummaryMemory"])

            self.memory_k = QSpinBox()
            self.memory_k.setRange(1, 100)
            self.memory_k.setValue(5)

            self.memory_layout.addRow("Memory Type:", self.memory_type)
            self.memory_layout.addRow("Memory K:", self.memory_k)

            # Save Button
            self.save_button = QPushButton("Save")
            self.save_button.clicked.connect(self.accept)
            self.layout.addWidget(self.save_button)
        except Exception as e:
            logging.error(f"Error in SettingsDialog: {str(e)}")

class ChatbotApp(QMainWindow):
    def __init__(self):
        super().__init__()
        try:
            self.stream_handler = StreamHandler()
            self.stream_handler.new_token.connect(self.update_chat_display)
            self.llm = None  # Initialize llm as None
            self.memory = ConversationBufferMemory()
            self.prompt_template = ChatPromptTemplate.from_messages([
                ("system", "You are a helpful AI assistant."),
                ("human", "{input}"),
                ("ai", "{output}"),
            ])
            self.chat_thread = None
            self.current_ai_message = None
            self.initUI()
        except Exception as e:
            logging.error(f"Error in ChatbotApp initialization: {str(e)}")
            QMessageBox.critical(self, "Error", f"Failed to initialize the application: {str(e)}")

    def initUI(self):
        try:
            self.setWindowTitle('Ollama Chatbot v0.1')
            self.resize(600, 850)  # Set initial size
            self.center()  # Center the window on the screen
            
            # Create central widget and main layout
            central_widget = QWidget()
            self.setCentralWidget(central_widget)
            main_layout = QVBoxLayout(central_widget)
            main_layout.setSpacing(15)

            self.systemMessageLabel = QLabel()  # Add this line
            self.systemMessageLabel.setFont(QFont('Arial', 10))
            self.systemMessageLabel.setStyleSheet("color: gray;")
            main_layout.addWidget(self.systemMessageLabel)  # Add this line
            
            # Create menu bar
            menubar = self.menuBar()
            
            # File menu
            file_menu = menubar.addMenu('File')
            
            new_chat_action = QAction('New Chat', self)
            new_chat_action.setShortcut('Ctrl+N')
            new_chat_action.triggered.connect(self.new_chat)
            file_menu.addAction(new_chat_action)
            
            save_chat_action = QAction('Save Chat', self)
            save_chat_action.setShortcut('Ctrl+S')
            save_chat_action.triggered.connect(self.save_chat)
            file_menu.addAction(save_chat_action)
            
            load_chat_action = QAction('Load Chat', self)
            load_chat_action.setShortcut('Ctrl+O')
            load_chat_action.triggered.connect(self.load_chat)
            file_menu.addAction(load_chat_action)
            
            export_chat_action = QAction('Export Chat', self)
            export_chat_action.triggered.connect(self.export_chat)
            file_menu.addAction(export_chat_action)
            
            # Edit menu
            edit_menu = menubar.addMenu('Edit')
            
            clear_chat_action = QAction('Clear Chat', self)
            clear_chat_action.triggered.connect(self.clear_chat)
            edit_menu.addAction(clear_chat_action)
            
            copy_last_message_action = QAction('Copy Last Message', self)
            copy_last_message_action.setShortcut('Ctrl+C')
            copy_last_message_action.triggered.connect(self.copy_last_message)
            edit_menu.addAction(copy_last_message_action)
            
            # View menu
            view_menu = menubar.addMenu('View')
            
            toggle_dark_mode_action = QAction('Toggle Dark Mode', self)
            toggle_dark_mode_action.triggered.connect(self.toggle_dark_mode)
            view_menu.addAction(toggle_dark_mode_action)
            
            # Model menu
            model_menu = menubar.addMenu('Model')        
            change_model_action = QAction('Change Model', self)
            change_model_action.triggered.connect(self.change_model_dialog)
            model_menu.addAction(change_model_action)
            
            show_available_models_action = QAction('Show Available Models', self)
            show_available_models_action.triggered.connect(self.listModels)
            model_menu.addAction(show_available_models_action)
            
            # Settings menu
            settings_menu = menubar.addMenu('Settings')
            open_settings_action = QAction('Open Settings', self)
            open_settings_action.triggered.connect(self.open_settings)
            settings_menu.addAction(open_settings_action)

            show_system_info_action = QAction('Show System Info', self)  # Add this line
            show_system_info_action.triggered.connect(self.show_system_info)  # Add this line
            settings_menu.addAction(show_system_info_action)  # Add this line
            
            # Help menu
            help_menu = menubar.addMenu('Help')
            
            about_action = QAction('About', self)
            about_action.triggered.connect(self.show_about)
            help_menu.addAction(about_action)
            
            self.chat_area = QScrollArea()
            self.chat_area.setWidgetResizable(True)
            self.chat_content = QWidget()
            self.chat_layout = QVBoxLayout(self.chat_content)
            self.chat_layout.setAlignment(Qt.AlignTop)
            self.chat_area.setWidget(self.chat_content)
            main_layout.addWidget(self.chat_area)
            
            input_layout = QHBoxLayout()
            
            self.inputField = QLineEdit()
            self.inputField.setPlaceholderText("Type your message here...")
            self.inputField.setFont(QFont('Arial', 12))
            self.inputField.returnPressed.connect(self.sendMessage)
            input_layout.addWidget(self.inputField)
            
            self.sendButton = QPushButton('Send')
            self.sendButton.setFont(QFont('Arial', 12))
            self.sendButton.setStyleSheet("""
                QPushButton {
                    background-color: #4CAF50;
                    color: white;
                    padding: 10px;
                    border: none;
                    border-radius: 5px;
                }
                QPushButton:hover {
                    background-color: #45a049;
                }
            """)
            self.sendButton.clicked.connect(self.sendMessage)
            input_layout.addWidget(self.sendButton)
            
            main_layout.addLayout(input_layout)
            
            palette = QPalette()
            palette.setColor(QPalette.Window, QColor("#E5DDD5"))
            self.setPalette(palette)

            # Initialize the model
            self.change_model()
        except Exception as e:
            logging.error(f"Error in initUI: {str(e)}")
            QMessageBox.critical(self, "Error", f"Failed to initialize the user interface: {str(e)}")

    def center(self):
        try:
            qr = self.frameGeometry()
            cp = QDesktopWidget().availableGeometry().center()
            qr.moveCenter(cp)
            self.move(qr.topLeft())
        except Exception as e:
            logging.error(f"Error centering window: {str(e)}")

    def open_settings(self):
        try:
            settings_dialog = SettingsDialog(self)
            if settings_dialog.exec_():
                # Update LLM settings
                self.change_model()
        except Exception as e:
            logging.error(f"Error opening settings: {str(e)}")
            QMessageBox.critical(self, "Error", f"Failed to open settings: {str(e)}")

    def change_model(self):
        try:
            settings_dialog = self.findChild(SettingsDialog)
            if settings_dialog:
                self.llm = ChatOllama(
                    model="gemma2:2b",  # Default model
                    temperature=settings_dialog.temperature.value(),
                    num_ctx=settings_dialog.num_ctx.value(),
                    num_gpu=settings_dialog.num_gpu.value(),
                    num_thread=settings_dialog.num_thread.value(),
                    top_k=settings_dialog.top_k.value(),
                    top_p=settings_dialog.top_p.value(),
                    repeat_penalty=settings_dialog.repeat_penalty.value(),
                    repeat_last_n=settings_dialog.repeat_last_n.value(),
                    seed=settings_dialog.seed.value(),
                    mirostat=int(settings_dialog.mirostat.currentText()),
                    mirostat_tau=settings_dialog.mirostat_tau.value(),
                    mirostat_eta=settings_dialog.mirostat_eta.value(),
                    f16_kv=settings_dialog.f16_kv.isChecked(),
                    logits_all=settings_dialog.logits_all.isChecked(),
                    vocab_only=settings_dialog.vocab_only.isChecked(),
                    streaming=True,
                    callbacks=[self.stream_handler],
                )
            else:
                self.llm = ChatOllama(
                    model="gemma2:2b",  # Default model
                    temperature=0.8,
                    streaming=True,
                    callbacks=[self.stream_handler],
                )
            self.add_system_message("The gemma2:2b model is loaded")
        except Exception as e:
            logging.error(f"Error changing model: {str(e)}")
            QMessageBox.critical(self, "Error", f"Failed to change model: {str(e)}")
            self.llm = None

    def add_system_message(self, message):
        try:
            self.systemMessageLabel.setText(message)
        except Exception as e:
            logging.error(f"Error adding system message: {str(e)}")
            QMessageBox.warning(self, "Warning", f"Failed to add system message: {str(e)}")

    def sendMessage(self):
        try:
            userMessage = self.inputField.text().strip()
            if not userMessage:
                return
            
            self.add_message(userMessage, is_user=True)
            self.inputField.clear()
            
            if self.llm is None:
                QMessageBox.warning(self, "Warning", "Model not loaded. Please check your settings and try again.")
                return

            self.memory.chat_memory.add_user_message(userMessage)
            messages = self.prompt_template.format_messages(input=userMessage, output="")
            messages.extend(self.memory.chat_memory.messages)
            self.chat_thread = ChatThread(self.llm, messages)
            self.chat_thread.response_ready.connect(self.handleResponse)
            self.chat_thread.error_occurred.connect(self.handleError)
            self.chat_thread.start()
            self.current_ai_message = MessageWidget("", is_user=False)
            self.chat_layout.addWidget(self.current_ai_message)
        except Exception as e:
            logging.error(f"Error sending message: {str(e)}")
            QMessageBox.critical(self, "Error", f"Failed to send message: {str(e)}")

    def handleResponse(self, response):
        try:
            if self.current_ai_message:
                self.current_ai_message.layout().itemAt(0).widget().setText(response)
                self.current_ai_message = None
                self.chat_area.verticalScrollBar().setValue(self.chat_area.verticalScrollBar().maximum())
                self.memory.chat_memory.add_ai_message(response)
        except Exception as e:
            logging.error(f"Error handling response: {str(e)}")
            QMessageBox.warning(self, "Warning", f"Failed to handle response: {str(e)}")

    def handleError(self, error_message):
        try:
            if "404" in error_message and "pull the model" in error_message:
                model_name = error_message.split("`ollama pull ")[-1].split("`")[0]
                reply = QMessageBox.question(self, "Model Not Found", 
                                             f"The model {model_name} is not found. Do you want to pull it?",
                                             QMessageBox.Yes | QMessageBox.No, QMessageBox.Yes)
                if reply == QMessageBox.Yes:
                    self.pullModel(model_name)
            else:
                QMessageBox.critical(self, "Error", f"{error_message}")
        except Exception as e:
            logging.error(f"Error handling error message: {str(e)}")
            QMessageBox.critical(self, "Critical Error", f"Failed to handle error message: {str(e)}")

    def listModels(self):
        try:
            ollama_path = self.find_ollama_executable()

            if not ollama_path:
                QMessageBox.critical(self, "Error", "Ollama executable not found. Please ensure Ollama is installed and added to your system's PATH.")
                return

            if sys.platform.startswith('win'):
                # Use PowerShell to run the command and keep the window open
                powershell_command = f'Start-Process powershell -ArgumentList "-NoExit", "-Command", "& \'{ollama_path}\' list"'
                subprocess.Popen(['powershell', '-Command', powershell_command], creationflags=subprocess.CREATE_NEW_CONSOLE)
            elif sys.platform.startswith('darwin'):  # macOS
                subprocess.Popen(['open', '-a', 'Terminal', ollama_path, 'list'])
            else:  # Linux/Unix
                subprocess.Popen(['x-terminal-emulator', '-e', f'{ollama_path} list'])

        except Exception as e:
            logging.error(f"Error listing models: {str(e)}")
            QMessageBox.critical(self, "Error", f"An error occurred while trying to list models: {str(e)}\nPlease check your Ollama installation and try again.")

    def pullModel(self, model_name):
        try:
            ollama_path = self.find_ollama_executable()

            if not ollama_path:
                QMessageBox.critical(self, "Error", "Ollama executable not found. Please ensure Ollama is installed and added to your system's PATH.")
                return

            if sys.platform.startswith('win'):
                # Use PowerShell to run the command and keep the window open
                powershell_command = f'Start-Process powershell -ArgumentList "-NoExit", "-Command", "& \'{ollama_path}\' pull {model_name}"'
                subprocess.Popen(['powershell', '-Command', powershell_command], creationflags=subprocess.CREATE_NEW_CONSOLE)
            elif sys.platform.startswith('darwin'):  # macOS
                subprocess.Popen(['open', '-a', 'Terminal', ollama_path, 'pull', model_name])
            else:  # Linux/Unix
                subprocess.Popen(['x-terminal-emulator', '-e', f'{ollama_path} pull {model_name}'])

            QMessageBox.information(self, "Model Download", f"Downloading {model_name}. Please check the opened terminal for progress.")

        except Exception as e:
            logging.error(f"Error pulling model: {str(e)}")
            QMessageBox.critical(self, "Error", f"Failed to start model download: {str(e)}")

    def find_ollama_executable(self):
        try:
            possible_names = ['ollama']
            if sys.platform.startswith('win'):
                possible_names = ['ollama.exe']

            paths_to_search = []
            if sys.platform.startswith('win'):
                # Common installation paths on Windows
                paths_to_search.extend([
                    os.path.join(os.environ.get('LOCALAPPDATA', ''), 'Programs', 'Ollama', 'ollama.exe'),
                    os.path.join(os.environ.get('ProgramFiles', ''), 'Ollama', 'ollama.exe')
                ])
            else:
                # Common installation paths on Unix/Linux/Mac
                paths_to_search.extend([
                    '/usr/local/bin/ollama',
                    '/usr/bin/ollama',
                    os.path.expanduser('~/bin/ollama')
                ])

            # Search specified paths
            for name in possible_names:
                for path in paths_to_search:
                    if shutil.which(name):
                        return shutil.which(name)
                    if os.path.isfile(path):
                        return path

            # Fallback to shutil.which
            return shutil.which(possible_names[0])
        except Exception as e:
            logging.error(f"Error finding Ollama executable: {str(e)}")
            return None

    def update_chat_display(self, token: str):
        try:
            if self.current_ai_message:
                current_text = self.current_ai_message.layout().itemAt(0).widget().text()
                self.current_ai_message.layout().itemAt(0).widget().setText(current_text + token)
                self.chat_area.verticalScrollBar().setValue(self.chat_area.verticalScrollBar().maximum())
        except Exception as e:
            logging.error(f"Error updating chat display: {str(e)}")
            QMessageBox.warning(self, "Warning", f"Failed to update chat display: {str(e)}")

    def add_message(self, message, is_user=True):
        try:
            message_widget = MessageWidget(message, is_user)
            self.chat_layout.addWidget(message_widget)
            self.chat_area.verticalScrollBar().setValue(self.chat_area.verticalScrollBar().maximum())
        except Exception as e:
            logging.error(f"Error adding message: {str(e)}")
            QMessageBox.warning(self, "Warning", f"Failed to add message: {str(e)}")

    def new_chat(self):
        try:
            self.memory = ConversationBufferMemory()
            self.clear_chat()
            self.add_system_message("New chat started")
        except Exception as e:
            logging.error(f"Error starting new chat: {str(e)}")
            QMessageBox.critical(self, "Error", f"Failed to start new chat: {str(e)}")

    def save_chat(self):
        try:
            file_name, _ = QFileDialog.getSaveFileName(self, "Save Chat", "", "JSON Files (*.json)")
            if file_name:
                chat_data = {
                    "messages": [{"type": msg.type, "content": msg.content} for msg in self.memory.chat_memory.messages],
                    "model": self.llm.model if self.llm else "gemma2:2b"  # Use current model or default
                }
                with open(file_name, 'w') as f:
                    json.dump(chat_data, f)
                self.add_system_message(f"Chat saved to {file_name}")
        except Exception as e:
            logging.error(f"Error saving chat: {str(e)}")
            QMessageBox.critical(self, "Error", f"Failed to save chat: {str(e)}")

    def load_chat(self):
        try:
            file_name, _ = QFileDialog.getOpenFileName(self, "Load Chat", "", "JSON Files (*.json)")
            if file_name:
                with open(file_name, 'r') as f:
                    chat_data = json.load(f)
                self.memory.chat_memory.messages = [
                    (msg["type"], msg["content"]) for msg in chat_data["messages"]
                ]
                self.change_model()
                self.clear_chat()
                for msg_type, content in self.memory.chat_memory.messages:
                    self.add_message(content, is_user=(msg_type == "human"))
                self.add_system_message(f"Chat loaded from {file_name}")
        except Exception as e:
            logging.error(f"Error loading chat: {str(e)}")
            QMessageBox.critical(self, "Error", f"Failed to load chat: {str(e)}")

    def export_chat(self):
        try:
            file_name, _ = QFileDialog.getSaveFileName(self, "Export Chat", "", "Text Files (*.txt)")
            if file_name:
                with open(file_name, 'w') as f:
                    for message in self.memory.chat_memory.messages:
                        f.write(f"{'User' if message.type == 'human' else 'AI'}: {message.content}\n\n")
                self.add_system_message(f"Chat exported to {file_name}")
        except Exception as e:
            logging.error(f"Error exporting chat: {str(e)}")
            QMessageBox.critical(self, "Error", f"Failed to export chat: {str(e)}")

    def clear_chat(self):
        try:
            for i in reversed(range(self.chat_layout.count())): 
                self.chat_layout.itemAt(i).widget().setParent(None)
        except Exception as e:
            logging.error(f"Error clearing chat: {str(e)}")
            QMessageBox.warning(self, "Warning", f"Failed to clear chat: {str(e)}")

    def copy_last_message(self):
        try:
            if self.chat_layout.count() > 0:
                last_message = self.chat_layout.itemAt(self.chat_layout.count() - 1).widget()
                QApplication.clipboard().setText(last_message.layout().itemAt(0).widget().text())
                self.add_system_message("Last message copied to clipboard")
            else:
                QMessageBox.warning(self, "Warning", "No messages to copy")
        except Exception as e:
            logging.error(f"Error copying last message: {str(e)}")
            QMessageBox.warning(self, "Warning", f"Failed to copy last message: {str(e)}")

    def change_model_dialog(self):
        try:
            models = [
                "smollm:135m", "smollm:360m", "qwen2.5:0.5b", "qwen2.5:1.5b",
                "deepseek-coder:1.3b", "yi-coder:1.5b", "stablelm2:1.6b",
                "smollm:1.7b", "gemma2:2b", "qwen2.5:3b", "phi3.5:3.8b",
                "yi:6b", "deepseek-coder:6.7b", "qwen2.5:7b", "llama3.1:8b",
                "gemma2:9b", "yi:9b", "yi-coder:9b", "mistral-nemo:12b",
                "qwen2.5:14b", "gemma2:27b"
            ]
            default_model = "gemma2:2b"
            default_index = models.index(default_model)
            model, ok = QInputDialog.getItem(self, 'Change Model', 'Select a model:', models, default_index, False)
            if ok and model:
                self.llm = ChatOllama(
                    model=model,
                    temperature=self.temperature.value(),
                    streaming=True,
                    callbacks=[self.stream_handler],
                )
                self.add_system_message(f"Model changed to {model}")
        except Exception as e:
            logging.error(f"Error changing model: {str(e)}")
            QMessageBox.warning(self, "Warning", f"Failed to change model: {str(e)}")

    def open_settings(self):
        try:
            settings_dialog = SettingsDialog(self)
            if settings_dialog.exec_():
                # Update LLM settings
                self.change_model()
        except Exception as e:
            logging.error(f"Error opening settings: {str(e)}")
            QMessageBox.critical(self, "Error", f"Failed to open settings: {str(e)}")

    def show_system_info(self):
        try:
            # Get CPU information
            cpu_info = platform.processor()
            cpu_cores = psutil.cpu_count(logical=True)
            cpu_freq = psutil.cpu_freq().current

            # Get RAM information
            ram = psutil.virtual_memory()
            total_ram = ram.total / (1024 ** 3)
            available_ram = ram.available / (1024 ** 3)

            # Get GPU information (if available)
            gpus = GPUtil.getGPUs()
            gpu_info = ""
            total_gpu_vram = 0
            if gpus:
                for gpu in gpus:
                    gpu_info += f"<li>Name: {gpu.name}</li>"
                    gpu_info += f"<li>VRAM: {gpu.memoryTotal:.2f} GB</li>"
                    total_gpu_vram += gpu.memoryTotal
            else:
                gpu_info = "<li>No GPU detected.</li>"

            # Start of Selection
            # Estimate maximum model size based on available RAM and GPU VRAM
            # Assuming 0.6 GB per billion parameters (Q4_0 quantization) with additional overhead

            bytes_per_billion_params = 0.6  # GB per billion parameters

            # Calculate model size based on available RAM
            ram_model_size = available_ram / bytes_per_billion_params

            # Calculate model size based on GPU VRAM, if available
            if gpus:
                gpu_model_size = total_gpu_vram / bytes_per_billion_params
            else:
                gpu_model_size = float('inf')  # No GPU limit if GPU is not available

            # The maximum model size is constrained by both RAM and GPU VRAM
            max_model_size = min(ram_model_size, gpu_model_size)

            if max_model_size >= 1:
                model_size_unit = "B"
            else:
                max_model_size = int(max_model_size * 1000)  # Convert to millions
                model_size_unit = "M"

            # Create a colorful HTML message for system information
            html_message = f"""
            <html>
            <head>
                <style>
                    body {{ font-family: Arial, sans-serif; }}
                    h2 {{ color: #2c3e50; }}
                    .info {{ margin-left: 20px; }}
                    .highlight {{ color: #27ae60; font-weight: bold; }}
                </style>
            </head>
            <body>
                <h2>System Information</h2>
                <div class="info">
                    <h3>CPU</h3>
                    <ul>
                        <li>Processor: {cpu_info}</li>
                        <li>Cores: {cpu_cores}</li>
                        <li>Frequency: {cpu_freq:.2f} GHz</li>
                    </ul>
                    <h3>RAM</h3>
                    <ul>
                        <li>Total: {total_ram:.2f} GB</li>
                        <li>Available: {available_ram:.2f} GB</li>
                    </ul>
                    <h3>GPU</h3>
                    <ul>
                        {gpu_info}
                    </ul>
                    <h3>Estimated Maximum Model Size (Q4_0 Quantization)</h3>
                    <p>Based on your hardware, you can likely run models up to <span class="highlight">{round(max_model_size, 1)} {model_size_unit}</span> parameters locally using Q4_0 quantization.</p>
                    <p>Note: This estimate assumes Q4_0 quantization and is approximate. Actual performance may vary depending on other factors.</p>
                </div>
            </body>
            </html>
            """

            # Display the system information in a message box with HTML formatting
            msg_box = QMessageBox(self)
            msg_box.setWindowTitle("System Information")
            msg_box.setText(html_message)
            msg_box.setTextFormat(Qt.RichText)
            msg_box.exec_()

        except Exception as e:
            logging.error(f"Error showing system info: {str(e)}")
            QMessageBox.warning(self, "Warning", f"Failed to show system info: {str(e)}")

    def save_chat(self):
        try:
            file_name, _ = QFileDialog.getSaveFileName(self, "Save Chat", "", "JSON Files (*.json)")
            if file_name:
                chat_data = {
                    "messages": [{"type": msg.type, "content": msg.content} for msg in self.memory.chat_memory.messages],
                    "model": self.llm.model if self.llm else "gemma2:2b"  # Use current model or default
                }
                with open(file_name, 'w') as f:
                    json.dump(chat_data, f)
                self.add_system_message(f"Chat saved to {file_name}")
        except Exception as e:
            logging.error(f"Error saving chat: {str(e)}")
            QMessageBox.warning(self, "Warning", f"Failed to save chat: {str(e)}")

    def load_chat(self):
        file_name, _ = QFileDialog.getOpenFileName(self, "Load Chat", "", "JSON Files (*.json)")
        if file_name:
            with open(file_name, 'r') as f:
                chat_data = json.load(f)
            self.memory.chat_memory.messages = [
                (msg["type"], msg["content"]) for msg in chat_data["messages"]
            ]
            self.change_model()
            self.clear_chat()
            for msg_type, content in self.memory.chat_memory.messages:
                self.add_message(content, is_user=(msg_type == "human"))
            self.add_system_message(f"Chat loaded from {file_name}")

    def export_chat(self):
        file_name, _ = QFileDialog.getSaveFileName(self, "Export Chat", "", "Text Files (*.txt)")
        if file_name:
            with open(file_name, 'w') as f:
                for message in self.memory.chat_memory.messages:
                    f.write(f"{'User' if message.type == 'human' else 'AI'}: {message.content}\n\n")
            self.add_system_message(f"Chat exported to {file_name}")

    def clear_chat(self):
        for i in reversed(range(self.chat_layout.count())): 
            self.chat_layout.itemAt(i).widget().setParent(None)

    def copy_last_message(self):
        if self.chat_layout.count() > 0:
            last_message = self.chat_layout.itemAt(self.chat_layout.count() - 1).widget()
            QApplication.clipboard().setText(last_message.layout().itemAt(0).widget().text())
            self.add_system_message("Last message copied to clipboard")

    def toggle_dark_mode(self):
        if self.palette().color(QPalette.Window).lightness() > 128:
            # Switch to dark mode
            palette = QPalette()
            # Window background (Deep navy blue)
            palette.setColor(QPalette.Window, QColor("#1A1A2E"))
            # Window text (Light gray)
            palette.setColor(QPalette.WindowText, QColor("#E0E0E0"))
            # Base color for widgets (Darker navy blue)
            palette.setColor(QPalette.Base, QColor("#16213E"))
            # Alternate base color (Rich dark blue)
            palette.setColor(QPalette.AlternateBase, QColor("#0F3460"))
            # Tooltip background (Darker navy blue)
            palette.setColor(QPalette.ToolTipBase, QColor("#16213E"))
            # Tooltip text (Light gray)
            palette.setColor(QPalette.ToolTipText, QColor("#E0E0E0"))
            # Text color (Black)
            palette.setColor(QPalette.Text, QColor("#000000"))
            # Button color (Rich dark blue)
            palette.setColor(QPalette.Button, QColor("#0F3460"))
            # Button text (Light gray)
            palette.setColor(QPalette.ButtonText, QColor("#E0E0E0"))
            # Bright text (Vibrant pink)
            palette.setColor(QPalette.BrightText, QColor("#E94560"))
            # Link color (Bright blue)
            palette.setColor(QPalette.Link, QColor("#4D9DE0"))
            # Highlight color (Bright blue)
            palette.setColor(QPalette.Highlight, QColor("#4D9DE0"))
            # Highlighted text (Deep navy blue)
            palette.setColor(QPalette.HighlightedText, QColor("#1A1A2E"))
            self.setPalette(palette)
            
            # Set menu bar background to dark color
            self.menuBar().setStyleSheet("QMenuBar { background-color: #0F3460; color: #E0E0E0; }")
        else:
            # Switch to light mode
            palette = QPalette()
            # Window background (Light gray)
            palette.setColor(QPalette.Window, QColor("#F5F5F5"))
            # Window text (Dark gray)
            palette.setColor(QPalette.WindowText, QColor("#212121"))
            # Base color for widgets (White)
            palette.setColor(QPalette.Base, QColor("#FFFFFF"))
            # Alternate base color (Light gray)
            palette.setColor(QPalette.AlternateBase, QColor("#E0E0E0"))
            # Tooltip background (White)
            palette.setColor(QPalette.ToolTipBase, QColor("#FFFFFF"))
            # Tooltip text (Dark gray)
            palette.setColor(QPalette.ToolTipText, QColor("#212121"))
            # Text color (Dark gray)
            palette.setColor(QPalette.Text, QColor("#212121"))
            # Button color (Light gray)
            palette.setColor(QPalette.Button, QColor("#E0E0E0"))
            # Button text (Dark gray)
            palette.setColor(QPalette.ButtonText, QColor("#212121"))
            # Bright text (Red)
            palette.setColor(QPalette.BrightText, QColor("#D32F2F"))
            # Link color (Blue)
            palette.setColor(QPalette.Link, QColor("#1976D2"))
            # Highlight color (Light blue)
            palette.setColor(QPalette.Highlight, QColor("#2196F3"))
            # Highlighted text (White)
            palette.setColor(QPalette.HighlightedText, QColor("#FFFFFF"))
            self.setPalette(palette)

            # Reset menu bar background to light color
            self.menuBar().setStyleSheet("QMenuBar { background-color: #F5F5F5; color: #212121; }")

    def change_model_dialog(self):
        try:
            models = [
                "smollm:135m", "smollm:360m", "qwen2.5:0.5b", "qwen2.5:1.5b",
                "deepseek-coder:1.3b", "yi-coder:1.5b", "stablelm2:1.6b",
                "smollm:1.7b", "gemma2:2b", "qwen2.5:3b", "phi3.5:3.8b",
                "yi:6b", "deepseek-coder:6.7b", "qwen2.5:7b", "llama3.1:8b",
                "gemma2:9b", "yi:9b", "yi-coder:9b", "mistral-nemo:12b",
                "qwen2.5:14b", "gemma2:27b"
            ]
            default_model = "gemma2:2b"
            default_index = models.index(default_model)

            dialog = QDialog(self)
            dialog.setWindowTitle("Change Model")
            layout = QVBoxLayout(dialog)

            model_combo = QComboBox()
            model_combo.addItems(models)
            model_combo.setCurrentIndex(default_index)
            layout.addWidget(model_combo)

            custom_model_checkbox = QCheckBox("Enter custom model name:")
            layout.addWidget(custom_model_checkbox)

            custom_model_edit = QLineEdit()
            custom_model_edit.setEnabled(False)  # Initially disabled
            layout.addWidget(custom_model_edit)

            # Connect checkbox to enable/disable the line edit
            custom_model_checkbox.stateChanged.connect(lambda state: custom_model_edit.setEnabled(state == Qt.Checked))

            buttons = QDialogButtonBox(QDialogButtonBox.Ok | QDialogButtonBox.Cancel, Qt.Horizontal, dialog)
            buttons.accepted.connect(dialog.accept)
            buttons.rejected.connect(dialog.reject)
            layout.addWidget(buttons)

            if dialog.exec_() == QDialog.Accepted:
                if custom_model_checkbox.isChecked():
                    model = custom_model_edit.text().strip()
                else:
                    model = model_combo.currentText()

                if model:
                    try:
                        self.llm = ChatOllama(
                            model=model,
                            streaming=True,
                            callbacks=[self.stream_handler],
                        )
                        self.add_system_message(f"The {model} model is loaded")
                    except Exception as e:
                        logging.error(f"Error loading model: {str(e)}")
                        QMessageBox.critical(self, "Error", f"Failed to load model: {str(e)}")
                        self.llm = None

        except Exception as e:
            logging.error(f"Error changing model: {str(e)}")
            QMessageBox.warning(self, "Warning", f"Failed to change model: {str(e)}")

    def show_about(self):
        QMessageBox.about(self, "About Ollama Chatbot", 
                          "Ollama Chatbot v2.2\n\n"
                          "A simple chatbot interface for Ollama models.\n"
                          "Created using PyQt5 and LangChain.\n\n"
                          "© 2024 github.com/mshojaei77")

if __name__ == '__main__':
    app = QApplication(sys.argv)
    chatbot = ChatbotApp()
    chatbot.show()
    sys.exit(app.exec_())
